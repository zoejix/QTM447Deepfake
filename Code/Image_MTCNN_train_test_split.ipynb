{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia2CLMAiDMm2"
      },
      "source": [
        "# Data cleaning and MTCNN for face cropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9oCChYuDTrf",
        "outputId": "156a858d-33f5-4ebd-b8ec-6de39f2e08d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WF5TPLKqdHG",
        "outputId": "885ceaf5-466e-4a1f-f9a2-515c1ef09b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            image_name        folder_name class\n",
            "0      malvlezlqf_fake  dfdc_train_part_8  fake\n",
            "1      mbcasihfhc_fake  dfdc_train_part_8  fake\n",
            "2      mboqxfdrso_fake  dfdc_train_part_8  fake\n",
            "3      mathczokbt_fake  dfdc_train_part_8  fake\n",
            "4      mcesdhhpkp_fake  dfdc_train_part_8  fake\n",
            "...                ...                ...   ...\n",
            "19905  falturjtfd_fake  dfdc_train_part_7  fake\n",
            "19906  fbauuanxsc_fake  dfdc_train_part_7  fake\n",
            "19907  fcmdzspgeh_fake  dfdc_train_part_7  fake\n",
            "19908  fbjdjgthyh_fake  dfdc_train_part_7  fake\n",
            "19909  fbnveezzal_fake  dfdc_train_part_7  fake\n",
            "\n",
            "[19910 rows x 3 columns]\n",
            "\n",
            "class\n",
            "fake    17398\n",
            "real     2512\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "src_directory = '/content/drive/MyDrive/deepfake_jpg/original_image'  # Source directory with original images\n",
        "\n",
        "# Initialize lists to store data\n",
        "image_names = []\n",
        "folder_names = []\n",
        "classes = []\n",
        "\n",
        "# Iterate over each folder in the src_directory\n",
        "for folder_name in os.listdir(src_directory):\n",
        "    folder_path = os.path.join(src_directory, folder_name)\n",
        "\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            # Extract image name and class from file name\n",
        "            image_name, file_extension = os.path.splitext(file_name)\n",
        "            image_class = \"real\" if \"_real\" in image_name else \"fake\"\n",
        "\n",
        "            # Append data to lists\n",
        "            image_names.append(image_name)\n",
        "            folder_names.append(folder_name)\n",
        "            classes.append(image_class)\n",
        "\n",
        "# Create DataFrame\n",
        "data = {'image_name': image_names, 'folder_name': folder_names, 'class': classes}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "print(\"\")\n",
        "print(df['class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2IyP-GdAM_f"
      },
      "source": [
        "## Face detection with MTCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ArFIOZwAa7L",
        "outputId": "d58fba9f-ae3c-4093-a452-741db0911f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.25.2)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5waUQJSzAPvL",
        "outputId": "37a12539-208d-45e9-d16b-b77363829f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on folder: dfdc_test_part_0\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 635ms/step\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "Face 1 saved to /content/drive/MyDrive/deepfake_jpg/face_image_test/adohdulfwb.jpg\n",
            "1/1 [==============================] - 0s 280ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "Face 1 saved to /content/drive/MyDrive/deepfake_jpg/face_image_test/aassnaulhq.jpg\n",
            "1/1 [==============================] - 0s 287ms/step\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "30/30 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "No face or more than 2 faces found in acazlolrpz.jpg\n",
            "1/1 [==============================] - 0s 271ms/step\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "38/38 [==============================] - 1s 15ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Face 1 saved to /content/drive/MyDrive/deepfake_jpg/face_image_test/aayfryxljh.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 265ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7/7 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "Face 1 saved to /content/drive/MyDrive/deepfake_jpg/face_image_test/aomqqjipcp.jpg\n",
            "1/1 [==============================] - 0s 284ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5/5 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Face 1 saved to /content/drive/MyDrive/deepfake_jpg/face_image_test/apedduehoy.jpg\n",
            "1/1 [==============================] - 0s 270ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Face 1 saved to /content/drive/MyDrive/deepfake_jpg/face_image_test/aktnlyqpah.jpg\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Face 1 saved to /content/drive/MyDrive/deepfake_jpg/face_image_test/ahjnxtiamx.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-74b7dc3fbacd>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;31m# Detect faces in the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Only proceed with images with 1 face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mtcnn/mtcnn.py\u001b[0m in \u001b[0;36mdetect_faces\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# We pipe here each of the stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mtotal_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mtcnn/mtcnn.py\u001b[0m in \u001b[0;36m__stage1\u001b[0;34m(self, image, scales, stage_status)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mimg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mout0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import numpy as np\n",
        "\n",
        "src_directory = '/content/drive/MyDrive/deepfake_jpg/original_image'  # Source directory with original images\n",
        "face_directory = '/content/drive/MyDrive/deepfake_jpg/face_image'  # Destination directory for face images\n",
        "\n",
        "detector = MTCNN()\n",
        "\n",
        "# for each folder in the src_directory, go to the folder:\n",
        "for folder_name in os.listdir(src_directory):\n",
        "    folder_path = os.path.join(src_directory, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "      print(f'Working on folder: {folder_name}')\n",
        "      # for each file in the folder:\n",
        "      for filename in os.listdir(folder_path):\n",
        "          if filename.endswith('.jpg'):\n",
        "              # if the file is not already in the face_directory:\n",
        "              if filename not in os.listdir(face_directory):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                img = Image.open(img_path)\n",
        "                # Convert the image to RGB (required by MTCNN)\n",
        "                img = img.convert('RGB')\n",
        "                pixels = np.array(img)\n",
        "\n",
        "                # Detect faces in the image\n",
        "                results = detector.detect_faces(pixels)\n",
        "\n",
        "                # Only proceed with images with 1 face\n",
        "                if len(results) == 1:\n",
        "                  # Process each face found\n",
        "                  for i, result in enumerate(results):\n",
        "                      x, y, width, height = result['box']\n",
        "                      x, y = max(0, x), max(0, y) # Adjust for any negative pixel index\n",
        "                      face = img.crop((x, y, x + width, y + height)) # Crop the face from the image\n",
        "                      # Define the output path for the cropped face image\n",
        "                      face_filename = f\"{os.path.splitext(filename)[0]}.jpg\"\n",
        "                      face_path = os.path.join(face_directory, face_filename)\n",
        "                      # Save the cropped face image\n",
        "                      face.save(face_path)\n",
        "                      print(f\"Face {i+1} saved to {face_path}\")\n",
        "                else:\n",
        "                  print(f\"No face or more than 2 faces found in {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhhlGtLz4Upm",
        "outputId": "7518eecc-0c05-40bd-f87c-614e51d8a559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           image_name class        folder_name\n",
            "0     aqiwuvxump_fake  fake  dfdc_train_part_4\n",
            "1     ardijxbxdm_real  real  dfdc_train_part_4\n",
            "2     aqywnbekqk_fake  fake  dfdc_train_part_4\n",
            "3     arrprgeura_real  real  dfdc_train_part_4\n",
            "4     asgfrovmom_real  real  dfdc_train_part_4\n",
            "...               ...   ...                ...\n",
            "9398  xkbvqelobg_fake  fake  dfdc_train_part_9\n",
            "9399  aqufcpfqnd_fake  fake  dfdc_train_part_8\n",
            "9400  bhvssfromy_real  real  dfdc_train_part_9\n",
            "9401  pqywogwvke_fake  fake  dfdc_train_part_9\n",
            "9402  neipvzqojf_fake  fake  dfdc_train_part_9\n",
            "\n",
            "[9403 rows x 3 columns]\n",
            "\n",
            "class\n",
            "fake       8169\n",
            "real       1232\n",
            "unknown       2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "folder_name\n",
            "dfdc_train_part_1    1484\n",
            "dfdc_train_part_9    1443\n",
            "dfdc_train_part_2    1282\n",
            "dfdc_train_part_8    1255\n",
            "dfdc_train_part_0    1193\n",
            "dfdc_train_part_3    1133\n",
            "dfdc_train_part_4    1013\n",
            "dfdc_train_part_5     598\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Create a summary data frame\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "filename_list = []\n",
        "class_list = []\n",
        "pattern = re.compile(r'_(real|fake)\\.')\n",
        "face_directory = '/content/drive/MyDrive/deepfake_jpg/face_image'\n",
        "\n",
        "for filename in os.listdir(face_directory):\n",
        "\n",
        "    # Match class base on suffix\n",
        "    match = pattern.search(filename)\n",
        "    class_label = match.group(1) if match else 'unknown'\n",
        "\n",
        "    # Append the filename and text to the respective lists\n",
        "    image_name, file_extension = os.path.splitext(filename)\n",
        "    filename_list.append(image_name)\n",
        "    class_list.append(class_label)\n",
        "\n",
        "# Create a DataFrame with the filename and text\n",
        "face_df = pd.DataFrame({'image_name': filename_list, 'class': class_list})\n",
        "\n",
        "merged_df = pd.merge(face_df, df[['image_name', 'folder_name']], on='image_name', how='left')\n",
        "\n",
        "# Display the merged DataFrame\n",
        "print(merged_df)\n",
        "print(\"\")\n",
        "print(merged_df['class'].value_counts())\n",
        "print(\"\")\n",
        "print(merged_df['folder_name'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWMcDv83OZH0"
      },
      "outputs": [],
      "source": [
        "# Show some extracted faces\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "face_directory = '/content/drive/MyDrive/deepfake_jpg/face_image/train_set'\n",
        "\n",
        "image_files = [f for f in os.listdir(face_directory) if f.endswith('.jpg')]\n",
        "\n",
        "fake_count = 0\n",
        "real_count = 0\n",
        "selected_image_files = []\n",
        "\n",
        "for img_file in image_files:\n",
        "    if img_file.endswith('_fake.jpg') and fake_count < 5: # number of fake images\n",
        "        selected_image_files.append(img_file)\n",
        "        fake_count += 1\n",
        "    elif img_file.endswith('_real.jpg') and real_count < 4: # number of real images\n",
        "        selected_image_files.append(img_file)\n",
        "        real_count += 1\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10, 8))\n",
        "\n",
        "for ax, img_file in zip(axes.flatten(), selected_image_files):\n",
        "    img_path = os.path.join(face_directory, img_file)\n",
        "    image = mpimg.imread(img_path)\n",
        "    ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(img_file)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-test split"
      ],
      "metadata": {
        "id": "hPKJDBfViqp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# Define directories\n",
        "face_directory = '/content/drive/MyDrive/deepfake_jpg/face_image'\n",
        "train_set_directory = '/content/drive/MyDrive/deepfake_jpg/face_image/train_set'\n",
        "test_set_directory = '/content/drive/MyDrive/deepfake_jpg/face_image/test_set'\n",
        "\n",
        "for index, row in merged_df.iterrows():\n",
        "    image_name = row['image_name']\n",
        "    folder_name = row['folder_name']\n",
        "\n",
        "    source_path = os.path.join(face_directory, image_name + '.jpg')\n",
        "    if folder_name == 'dfdc_train_part_9':\n",
        "        destination_path = os.path.join(test_set_directory, image_name + '.jpg')\n",
        "    else:\n",
        "        destination_path = os.path.join(train_set_directory, image_name + '.jpg')\n",
        "\n",
        "    try:\n",
        "        # Move the image to the appropriate directory\n",
        "        shutil.move(source_path, destination_path)\n",
        "        print(f\"Moved {image_name} successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File {image_name} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error moving {image_name}: {e}\")\n"
      ],
      "metadata": {
        "id": "UC6P38zR0qQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_directory = '/content/drive/MyDrive/deepfake_jpg/face_image'\n",
        "train_set_directory = '/content/drive/MyDrive/deepfake_jpg/face_image/train_set'\n",
        "test_set_directory = '/content/drive/MyDrive/deepfake_jpg/face_image/test_set'\n",
        "\n",
        "\n",
        "face_files = os.listdir(face_directory)\n",
        "print(\"Number of files in face_directory:\", len(face_files))\n",
        "train_files = os.listdir(train_set_directory)\n",
        "print(\"Number of files in train_directory:\", len(train_files))\n",
        "test_files = os.listdir(test_set_directory)\n",
        "print(\"Number of files in test_directory:\", len(test_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6pUZ4XjmTPT",
        "outputId": "c4ad915c-b8a8-4cd5-e153-46fd448a7d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in face_directory: 2\n",
            "Number of files in train_directory: 7958\n",
            "Number of files in test_directory: 1443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU-7X2x5YUfy"
      },
      "source": [
        "## Base CNN Model (sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CwhvTZEY3Rt",
        "outputId": "cbcffa0b-145d-4083-fb25-cc87584f90b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 32, 32, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 16)        160       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 16)        64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 4, 4, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 725066 (2.77 MB)\n",
            "Trainable params: 724074 (2.76 MB)\n",
            "Non-trainable params: 992 (3.88 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Base CNN\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = keras.Input(shape=(32,32,1))\n",
        "\n",
        "# Rescale the input\n",
        "rescale_layer = layers.Rescaling(scale=1./255)(input_layer)\n",
        "\n",
        "x = layers.Conv2D(16, 3, padding=\"same\")(rescale_layer)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "for size in [32, 64, 128, 256]:\n",
        "    x = layers.Conv2D(size, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(2, strides=2, padding=\"same\")(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dense(units=256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "\n",
        "x = layers.Dense(units=256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "\n",
        "output_layer = layers.Dense(units=10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(input_layer,output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSEvEclVZLzw"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "#Create a model checkpoint\n",
        "# Define the filepath for saving the model\n",
        "filepath = 'base_cnn_deepfake.keras'\n",
        "\n",
        "# Create the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "# Add the callback to the list of callbacks in the fit() method\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "# Train the model and monitor the training and validation accuracy\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}